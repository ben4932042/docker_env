version: '2'
services:
  # jupyter:
  #   build:
  #     context: ./dockerfile
  #     dockerfile: dockerfile-jupyter
  #   container_name: jupyter
  #   hostname: jupyter
  #   ports:
  #     - "8888:8888"
  #   command: start-notebook.sh --NotebookApp.token=''
  #   volumes:
  #     - ./jupyter:/home/jovyan/Project
  #     - ./formal_code:/home/jovyan/work
  #   restart: always


  # formal_python_code:
  #   build:
  #     context: ./dockerfile
  #     dockerfile: dockerfile-python
  #   container_name: python
  #   tty: true
  #   stdin_open: true
  #   volumes:
  #     - ./formal_code:/app
  #   command: python app.py
  #   ports:
  #     - "5000:5000"
  #   restart: always

  # jupyter-keras:
  #   image: gaarv/jupyter-keras
  #   container_name: jupyter-keras
  #   hostname: jupyter-keras
  #   ports:
  #     - "8887:8888"
  #   command: start-notebook.sh --NotebookApp.token=''
  #   volumes:
  #     - ./jupyter-keras:/home/jovyan/Project
  #   restart: always


   mysql:
     image: mysql:5.6
     container_name: mysql
     hostname: mysql
     ports:
       - "3307:3306"
     environment:
       - MYSQL_ROOT_PASSWORD=iii
  #   volumes:
  #     - ./mysql_db/mysql_data:/var/lib/mysql
  #     - ./mysql_db/mysql_init:/docker-entrypoint-initdb.d/
     restart: always
   mongo:
     image: mongo
     container_name: mongodb
     hostname: mongodb
     restart: always
     expose:
       - 6016
     ports:
       - "27017:27017"

  # pyspark:
  #   image: orozcohsu/pyspark_mongo_ltu:v3  
  #   container_name: pyspark
  #   hostname: pyspark
  #   ports:
  #     - "8890:8888"
  #     - "4040:4040"
  #     - "4041:4041"
  #   command: start-notebook.sh --NotebookApp.token=''
  #   volumes:
  #     - ./pyspark:/pyspark
  #   restart: always

  # spark-master:
  #   image: bde2020/spark-master:2.4.5-hadoop2.7
  #   container_name: spark-master
  #   ports:
  #     - "8080:8080"
  #     - "7077:7077"
  #   environment:
  #     - INIT_DAEMON_STEP=setup_spark
  #     - "constraint:node==<Justice>"
  # spark-worker-1:
  #   image: bde2020/spark-worker:2.4.5-hadoop2.7
  #   container_name: spark-worker-1
  #   depends_on:
  #     - spark-master
  #   ports:
  #     - "7070:8081"
  #   environment:
  #     - "SPARK_MASTER=spark://spark-master:7077"
  #     - "constraint:node==<DoDo>"
  # spark-worker-2:
  #   image: bde2020/spark-worker:2.4.5-hadoop2.7
  #   container_name: spark-worker-2
  #   depends_on:
  #     - spark-master
  #   ports:
  #     - "7071:8081"
  #   environment:
  #     - "SPARK_MASTER=spark://spark-master:7077"
  #     - "constraint:node==<Ben>"


  # mongo:
  #   image: mongo
  # logstash:
  #   image: docker.elastic.co/logstash/logstash-oss:7.2.0
  #   container_name: logstash
  #   hostname: logstash
  #   restart: always
  #   volumes:
  #     - ./logstash/data:/usr/share/logstash/data:rw
  #     - ./logstash/template:/usr/share/logstash/template:ro
  #     #- ./logstash/logs:/usr/share/logstash/logs:rw
  #     - ./logstash/config/pipelines.yml:/usr/share/logstash/config/pipelines.yml:ro
  #     - ./logstash/pipeline:/usr/share/logstash/pipeline:ro
  #   ports:
  #     - "127.0.0.1:5000:5000/udp"
  #   environment:
  #     LS_JAVA_OPTS: "-Xmx256m -Xms256m"
  #   depends_on:
  #     - elasticsearch
